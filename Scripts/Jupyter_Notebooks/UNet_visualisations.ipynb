{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60d01217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BASE_DIR\"] = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling\"\n",
    "BASE_DIR = os.environ[\"BASE_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7435896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../Scripts/Functions/Climate_Indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de479224",
   "metadata": {},
   "source": [
    "Loading the saved quick check trained model from Downscaling_Models/UNet_Deterministic_training_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b39c5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/models_UNet/UNet_Deterministic_Training_Dataset/best_model_Huber_FULL_RLOP.pth\")\n",
    "training_checkpoint =torch.load(model_path,map_location=torch.device('cpu')) #Moving model to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c587ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#Checking the parameters and keys\n",
    "print(type(training_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a15f4478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "model_state_dict\n",
      "optimizer_state_dict\n",
      "loss\n"
     ]
    }
   ],
   "source": [
    "#Checking all model parameters \n",
    "for key in training_checkpoint.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c53c8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing UNet class from Unet.py\n",
    "sys.path.append(os.path.join(BASE_DIR, \"sasthana/Downscaling/Downscaling_Models/models_UNet/UNet_Deterministic_Training_Dataset\"))\n",
    "from UNet import UNet #Importing Unet class\n",
    "from Downscaling_Dataset_Prep import DownscalingDataset #for creating paired frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8386844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance= UNet(in_channels=5, out_channels=4)\n",
    "model_instance.load_state_dict(training_checkpoint[\"model_state_dict\"])\n",
    "model_instance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b7315a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaled datasets for test set (2011-2020) :loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ed96f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_input = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"RhiresD_input_test_chronological_scaled.nc\"))\n",
    "temp_input = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TabsD_input_test_chronological_scaled.nc\"))\n",
    "tmin_input= xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TminD_input_test_chronological_scaled.nc\"))\n",
    "tmax_input= xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TmaxD_input_test_chronological_scaled.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20ee32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"RhiresD_target_test_chronological_scaled.nc\"))\n",
    "temp_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TabsD_target_test_chronological_scaled.nc\"))\n",
    "tmin_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TminD_target_test_chronological_scaled.nc\"))\n",
    "tmax_target = xr.open_dataset(os.path.join(BASE_DIR, \"sasthana\", \"Downscaling\", \"Downscaling_Models\", \"Training_Chronological_Dataset\", \"TmaxD_target_test_chronological_scaled.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f45e4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the paired feature-target dataset; first loading individual and coverting them into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2718770d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DownscalingDataset.__init__() got an unexpected keyword argument 'var_name_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m precip_ds\u001b[38;5;241m=\u001b[39m \u001b[43mDownscalingDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecip_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecip_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRhiresD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m temp_ds \u001b[38;5;241m=\u001b[39m DownscalingDataset(temp_input, temp_target, var_name_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtas\u001b[39m\u001b[38;5;124m'\u001b[39m, var_name_targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTabsD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m tmin_ds \u001b[38;5;241m=\u001b[39m DownscalingDataset(tmin_input, tmin_target, var_name_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtasmin\u001b[39m\u001b[38;5;124m'\u001b[39m, var_name_targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTminD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: DownscalingDataset.__init__() got an unexpected keyword argument 'var_name_inputs'"
     ]
    }
   ],
   "source": [
    "precip_ds= DownscalingDataset(precip_input, precip_target, var_name_inputs=\"pr\", var_name_targets=\"RhiresD\")\n",
    "temp_ds = DownscalingDataset(temp_input, temp_target, var_name_inputs='tas', var_name_targets='TabsD')\n",
    "tmin_ds = DownscalingDataset(tmin_input, tmin_target, var_name_inputs='tasmin', var_name_targets='TminD')\n",
    "tmax_ds = DownscalingDataset(tmax_input, tmax_target, var_name_inputs='tasmax', var_name_targets='TmaxD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd20c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97fd54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9f4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now building paired dataset\n",
    "paired_ds= PairedDataset(precip_ds,temp_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c3c8a",
   "metadata": {},
   "source": [
    "A single prediction : not batch wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04d653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting one single image pair\n",
    "index=5\n",
    "input_img, target_img=paired_ds[index]\n",
    "input_img= input_img.unsqueeze(0)\n",
    "model_instance.eval()\n",
    "with torch.no_grad():\n",
    "    output_img=model_instance(input_img)\n",
    "\n",
    "output_img=output_img.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9dd5f",
   "metadata": {},
   "source": [
    "Whats the time coordinate of this index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cddc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_time_pr = precip_input['time'].isel(time=index).values\n",
    "corresponding_time_tas = temp_input['time'].isel(time=index).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b1b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975-06-26T00:00:00.000000000\n",
      "1975-06-26T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "print(corresponding_time_tas)\n",
    "print(corresponding_time_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35a56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img=input_img.squeeze(0)\n",
    "target_img=target_img.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02494438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 265, 370])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "857975e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img=output_img.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "450f99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 265, 370])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96651214",
   "metadata": {},
   "source": [
    "The channels were given in unison to the model. For visualisation , it has to be separated. I separate it here for both inpouts and outputs because they have to be plotted side by side for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33fbd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rhiresd= input_img[0,:,:]\n",
    "input_tabsd= input_img[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df0ba4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rhiresd=target_img[0,:,:]\n",
    "target_tabsd=target_img[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e9dbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rhiresd= output_img[0,:,:]\n",
    "predicted_tabsd= output_img[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b65af719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eec547",
   "metadata": {},
   "source": [
    "Plotting a single image : input and output image for rhiresd and tabsd side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a06af5",
   "metadata": {},
   "source": [
    "26 June,1975 (TEST SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lon_max = 5, 11\n",
    "lat_min, lat_max = 45, 48\n",
    "\n",
    "lons = np.linspace(lon_min, lon_max, input_rhiresd.shape[1])\n",
    "lats = np.linspace(lat_min, lat_max, input_rhiresd.shape[0])\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "\n",
    "\n",
    "lambert_proj = ccrs.LambertAzimuthalEqualArea(central_longitude=8, central_latitude=47)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 16), subplot_kw={'projection': lambert_proj})\n",
    "axes = axes.flatten()\n",
    "\n",
    "datasets = [\n",
    "    (input_rhiresd, '(Standardised) Input Precipitation', 'Blues'),\n",
    "    (input_tabsd, '(Standardised) Input Temperature', 'coolwarm'),\n",
    "    (predicted_rhiresd, 'Predicted Precipitation (RhiresD)', 'Blues'),\n",
    "    (predicted_tabsd, 'Predicted Temperature (TabsD)', 'coolwarm'),\n",
    "    (target_rhiresd, 'Ground Truth Precipitation (RhiresD)', 'Blues'),\n",
    "    (target_tabsd, 'Ground Truth Temperature (TabsD)', 'coolwarm')\n",
    "]\n",
    "\n",
    "for ax, (data, title, cmap) in zip(axes, datasets):\n",
    "    im = ax.pcolormesh(lon2d, lat2d, data, cmap=cmap, shading='auto', transform=ccrs.PlateCarree())\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.set_extent([lon2d.min(), lon2d.max(), lat2d.min(), lat2d.max()], crs=ccrs.PlateCarree())\n",
    "    cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.suptitle(f\"Test set: Bicubically interpolated inputs, predictions and ground truth on {corresponding_time_pr}\",)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940a3ef",
   "metadata": {},
   "source": [
    "Destandardisation of the above uzsing trainign set mean, std, min and max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22401ee",
   "metadata": {},
   "source": [
    "Inputs reversed with input normalization values (precip_min, precip_max, tas_mean, tas_std).\n",
    "\n",
    "Targets and Predictions are reversed with target normalization values (target_min, target_max, tabsd_mean, tabsd_std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f8688a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Standardise import standardise\n",
    "from Standardise import min_max_calculator\n",
    "from Standardise import norm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_precip_path = \"/data/processed/Bicubic/Train/features_precip_masked_bicubic_train.nc\"\n",
    "input_temp_path = \"/data/processed/Bicubic/Train/features_tas_masked_bicubic_train.nc\"\n",
    "\n",
    "target_precip_path = \"/data/processed/Bicubic/Train/targets_precip_masked_train.nc\"\n",
    "target_temp_path = \"/data/processed/Bicubic/Train/targets_tas_masked_train.nc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f8d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_precip_ds = xr.open_dataset(input_precip_path, chunks={\"time\": 100})\n",
    "input_temp_ds = xr.open_dataset(input_temp_path, chunks={\"time\": 100})\n",
    "target_precip_ds = xr.open_dataset(target_precip_path, chunks={\"time\": 100})\n",
    "target_temp_ds = xr.open_dataset(target_temp_path, chunks={\"time\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03368d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION PARAMETERS using your Standardise.py functions ---\n",
    "precip_min, precip_max = min_max_calculator(input_precip_ds, var_name=\"pr\")\n",
    "tas_mean, tas_std = norm_params(input_temp_ds, var_name=\"tas\")\n",
    "\n",
    "target_min, target_max = min_max_calculator(target_precip_ds, var_name=\"RhiresD\")\n",
    "tabsd_mean, tabsd_std = norm_params(target_temp_ds, var_name=\"TabsD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DESTANDARDIZE SINGLE IMAGES ---\n",
    "\n",
    "input_img = input_img.squeeze(0)   \n",
    "target_img = target_img.squeeze(0)\n",
    "output_img = output_img.squeeze(0)\n",
    "\n",
    "# Split channels\n",
    "input_rhiresd = input_img[0, :, :]\n",
    "input_tabsd = input_img[1, :, :]\n",
    "\n",
    "target_rhiresd = target_img[0, :, :]\n",
    "target_tabsd = target_img[1, :, :]\n",
    "\n",
    "predicted_rhiresd = output_img[0, :, :]\n",
    "predicted_tabsd = output_img[1, :, :]\n",
    "\n",
    "# --- Now destandardize each one ---\n",
    "\n",
    "# INPUTS (input normalization)\n",
    "input_rhiresd_orig = input_rhiresd * (precip_max - precip_min) + precip_min\n",
    "input_tabsd_orig = input_tabsd * tas_std + tas_mean\n",
    "\n",
    "target_rhiresd_orig = target_rhiresd * (target_max - target_min) + target_min\n",
    "target_tabsd_orig = target_tabsd * tabsd_std + tabsd_mean\n",
    "\n",
    "predicted_rhiresd_orig = predicted_rhiresd * (target_max - target_min) + target_min\n",
    "predicted_tabsd_orig = predicted_tabsd * tabsd_std + tabsd_mean\n",
    "\n",
    "\n",
    "print(\"Single input, output, and ground truth destandardized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8126de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting destandardised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5822394",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min, lon_max = 5, 11\n",
    "lat_min, lat_max = 45, 48\n",
    "\n",
    "lons = np.linspace(lon_min, lon_max, input_rhiresd_orig.shape[1])\n",
    "lats = np.linspace(lat_min, lat_max, input_rhiresd_orig.shape[0])\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "\n",
    "# Set Lambert projection\n",
    "lambert_proj = ccrs.LambertAzimuthalEqualArea(central_longitude=8, central_latitude=47)\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 16), subplot_kw={'projection': lambert_proj})\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create datasets: Now using DE-STANDARDIZED data\n",
    "datasets = [\n",
    "    (input_rhiresd_orig, 'Input Precipitation (De-standardized)', 'Blues'),\n",
    "    (input_tabsd_orig, 'Input Temperature (De-standardized)', 'coolwarm'),\n",
    "    (predicted_rhiresd_orig, 'Predicted Precipitation (De-standardized)', 'Blues'),\n",
    "    (predicted_tabsd_orig, 'Predicted Temperature (De-standardized)', 'coolwarm'),\n",
    "    (target_rhiresd_orig, 'Ground Truth Precipitation (RhiresD)', 'Blues'),\n",
    "    (target_tabsd_orig, 'Ground Truth Temperature (TabsD)', 'coolwarm')\n",
    "]\n",
    "\n",
    "# Plot\n",
    "for ax, (data, title, cmap) in zip(axes, datasets):\n",
    "    im = ax.pcolormesh(\n",
    "        lon2d, lat2d, data, cmap=cmap, shading='auto', transform=ccrs.PlateCarree(),\n",
    "        vmin=-10, vmax=25  \n",
    "    )\n",
    "    ax.set_title(title, fontsize=13)\n",
    "    ax.coastlines(resolution='10m')\n",
    "    ax.set_extent([lon2d.min(), lon2d.max(), lat2d.min(), lat2d.max()], crs=ccrs.PlateCarree())\n",
    "    cbar = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    cbar.set_label('Units', fontsize=10) \n",
    "\n",
    "# Global title\n",
    "plt.suptitle(f\"Test set: Bicubically interpolated inputs, predictions and ground truth (De-standardized)\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
