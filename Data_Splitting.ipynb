{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cc5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../Scripts/Functions\")\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client= Client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f3458",
   "metadata": {},
   "source": [
    "installed dask distributed, and used all 4 CPU cores, computing time reduced to 30 seconds per line!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e2d8e",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxCHECKING SHAPExxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a521ed2",
   "metadata": {},
   "source": [
    "Note that bicubic baseline was already split in the Downscaling sister repo. Here, I just do BILINEAR, for calcualting the test set metrics (RMSE and R^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56002d06",
   "metadata": {},
   "source": [
    "ONLY FOR BILINEAR BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6d6b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19358, 240, 370)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_precip = xr.open_dataset(\"Bilinear_Baselines/files/bilinear_rhiresd.nc\")[\"RhiresD\"]\n",
    "features_ds_precip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0e7da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19358, 240, 370)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_tabsd= xr.open_dataset(\"Bilinear_Baselines/files/bilinear_tabsd.nc\")[\"TabsD\"]\n",
    "features_ds_tabsd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1525a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19358, 240, 370)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_tmax= xr.open_dataset(\"Bilinear_Baselines/files/bilinear_tmax.nc\")[\"TmaxD\"]\n",
    "features_ds_tmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c68e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19358, 240, 370)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_tmin= xr.open_dataset(\"Bilinear_Baselines/files/bilinear_tmin.nc\")[\"TminD\"]\n",
    "features_ds_tmin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cff50f",
   "metadata": {},
   "source": [
    "The entire dataset will be divided into tain, test val for both bilinear and bicubic interpolation for calculating standardisation metric etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d02eb",
   "metadata": {},
   "source": [
    "All splits performed according to the function written in Functions/Train_Test_Val.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb711f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Train_Test_Val import split_by_decade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83041aff",
   "metadata": {},
   "source": [
    "Splitting features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf99a05",
   "metadata": {},
   "source": [
    "RhiresD, TabsD, Tmin, Tmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35fa5b",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1714fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_by_decade(\n",
    "    features_ds_precip,\n",
    "    \"Bilinear_Baselines/Features\",\n",
    "    \"rhiresd_features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128d2b1",
   "metadata": {},
   "source": [
    "SIMILAR TO ABOVE FOR OTHER THREE VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8577c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_by_decade(\n",
    "    features_ds_tmax,\n",
    "    \"Bilinear_Baselines/Features\",\n",
    "    \"tmax_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547908a",
   "metadata": {},
   "source": [
    "Splitting targets along the same lines here is not required, all targets will be the same (OBVIO) and stored in Bicubic_data_for_UNet/Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88d631",
   "metadata": {},
   "source": [
    "Standardisation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3811d",
   "metadata": {},
   "source": [
    "Standardisation has to be performed avoiding data leakage. Hence, the train -test contamination has to be avoided. \n",
    "\n",
    "Can be done using statistics only for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517db7f7",
   "metadata": {},
   "source": [
    "The mean, std, min, max and range of the training set will then be used to perform scaling for the test set as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e95d7",
   "metadata": {},
   "source": [
    "Standardisation has already been performed in the sister repo. As the metrics are calcualted after destandaridasation, it is not needed in this repo (FOR NOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813a446",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
